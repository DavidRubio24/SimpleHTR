{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "SimpleHTR - Model.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/DavidRubio24/SimpleHTR/blob/master/SimpleHTR_Model.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "ikICLOp6ThY7",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Este codigo está sacado de https://github.com/githubharald/SimpleHTR\n",
        "\n",
        "En concreto este código es Model.py\n",
        "\n",
        "Se le han añadido comentarios por todos lados para aclarar su funcionamiento."
      ]
    },
    {
      "metadata": {
        "id": "jh9m-0PvUe5_",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Los imports:\n",
        "\n",
        "*  __future__ trae caracteristicas de versiones futuras de python, así con python 2 este código también funciona.\n",
        "*  NumPy se usa para tratar vectores y matrices eficientemente.\n",
        "*  TensorFlow se usa para redes neuronales."
      ]
    },
    {
      "metadata": {
        "id": "v071L6TfUZXA",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from __future__ import division\n",
        "from __future__ import print_function\n",
        "\n",
        "import numpy as np\n",
        "import tensorflow as tf"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "io4kcebAVGaz",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Definimos un enumerado para identificar el algoritmo con el que e¡decidiremos cual es la palabras más razonable que cuadra."
      ]
    },
    {
      "metadata": {
        "id": "VwdFMuU7VV2k",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class DecoderType:\n",
        "  BestPath = 0\n",
        "  BeamSearch = 1\n",
        "  WordBeamSearch = 2"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "0hL2WmA7VX0O",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "La clase Model define una funcion parametrizable que hace predicciones. Entrenar el modelo consiste en elegir los paramaetros adecuados."
      ]
    },
    {
      "metadata": {
        "id": "PBk7H-7IXKXs",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Primero definimos unas constantes:\n",
        "\n",
        "*  Cantidad de ejemplos que usareos a la vez para entrenar el modelo.\n",
        "*  Tamaño de la imagen que aceptaremos. Se puede rellenar con blanco si la proporción no cuadra.\n",
        "*  Cantidad máxima de acracteres que nuestro modelo puede predecir que tiene la imágen."
      ]
    },
    {
      "metadata": {
        "id": "VTyRPevsW4qs",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class Model:\n",
        "  \"minimalistic TensorFlow model for Handwitten Text Recognition\"\n",
        "\n",
        "  # model constants\n",
        "  batchSize = 50\n",
        "  imgSize = (128, 32)\n",
        "  maxTextLen = 32"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Oh4CzYezXyEZ",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "(Para definir las funciones por separado en este Notebook pondremos *class Model(Model):* al principio de cada celda, es un truco un poco sucio, pero no hay otra forma mejor: https://github.com/jupyter/notebook/issues/1243) "
      ]
    },
    {
      "metadata": {
        "id": "lAXZuv1lYVoo",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Se inicializa el modelo.\n",
        "\n",
        "En todo este documento no se realiza ninguna operación. Solo se crea un grafo de computación que se ejecutará desde main.py."
      ]
    },
    {
      "metadata": {
        "id": "zzak7jNBX1f6",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class Model(Model):\n",
        "  def __init__(self, charList, decoderType=DecoderType.BestPath, mustRestore=False):\n",
        "    \"\"\" init model: add CNN, RNN and CTC and initialize TensorFlow\n",
        "\n",
        "        Hay que especificar los caracteres que queremos reconocer,\n",
        "        el tipo de busqueda en diccionario, si queremos seguir\n",
        "        entrenando (mustRestore=True) o empezar de cero y ¿snapID?\n",
        "    \"\"\"\n",
        "    self.charList = charList\n",
        "    self.decoderType = decoderType\n",
        "    self.mustRestore = mustRestore\n",
        "    self.snapID = 0\n",
        "\n",
        "    # Whether to use normalization over a batch or a population\n",
        "    self.is_train = tf.placeholder(tf.bool, name='is_train') # Los placeholders son datos que se proporcionarán más tarde, al hacer session.run(, feed_dict=)\n",
        "\n",
        "    # input image batch\n",
        "    self.inputImgs = tf.placeholder(tf.float32, shape=(None, Model.imgSize[0], Model.imgSize[1]))\n",
        "\n",
        "    # setup CNN, RNN and CTC\n",
        "    # Estas lineas son las importantes. Las funciones están explcadas más abajo.\n",
        "    self.setupCNN()\n",
        "    self.setupRNN()\n",
        "    self.setupCTC()\n",
        "\n",
        "    # setup optimizer to train NN\n",
        "    self.batchesTrained = 0\n",
        "    self.learningRate   = tf.placeholder(tf.float32, shape=[])\n",
        "    \n",
        "    # Las siguientes 2 lineas son unas dependencias que hay que procesar antes del algortmo de optimización\n",
        "    self.update_ops     = tf.get_collection(tf.GraphKeys.UPDATE_OPS) \n",
        "    with tf.control_dependencies(self.update_ops):\n",
        "      # Se optimiza loss con el algoritmo RMSPropOptimizer y ratio de aprendizaje self.learningRate\n",
        "      # Esta optimización irá cambiando los parametros del modelo para reducir loss\n",
        "      self.optimizer = tf.train.RMSPropOptimizer(self.learningRate).minimize(self.loss)\n",
        "\n",
        "    # initialize TF\n",
        "    (self.sess, self.saver) = self.setupTF()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "OQMP6xmVYcI-",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Las redes neuronales convolucionales (CNN) se usan para visión artificial.\n",
        "\n",
        "A partir de la imágen original extraen ciertar caracteristicas pasandoles filtros (kernels) de distintos tamaños (tipocamente 3x3, 5x5 o incluso 7x7).\n",
        "Cada filtro genera un canal de una imagen nueva en la que se destacan las caracteristicas que buscaba ese filtro."
      ]
    },
    {
      "metadata": {
        "id": "GQ4jgYyEYesw",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class Model(Model):\n",
        "  def setupCNN(self):\n",
        "    \"create CNN layers and return output of these layers\"\n",
        "    # La imagen tiene 2 dimensiones, pero tenemos que añadirle una más porque vamos a trabajar con varios canales\n",
        "    cnnIn4d = tf.expand_dims(input=self.inputImgs, axis=3)\n",
        "\n",
        "    # list of parameters for the layers\n",
        "    kernelVals = [5, 5, 3, 3, 3]              # Tamaño de los filtros (nº de pixels que tiene el lado)\n",
        "    featureVals = [1, 32, 64, 128, 128, 256]  # Nº de canales que leen los filtros de la i-esima layer\n",
        "    strideVals = poolVals = [(2,2), (2,2), (1,2), (1,2), (1,2)]  #Cada cuantos pixels se aplica el filtro\n",
        "    numLayers = len(strideVals)  # Nº de capas de filtros\n",
        "\n",
        "    # Create layers\n",
        "    pool = cnnIn4d # input to first CNN layer\n",
        "    \n",
        "    for i in range(numLayers):\n",
        "    # Por cada layer:\n",
        "      # Generamos aleatoriamente featureVals[i + 1] filtros de kernelVals[i]xkernelVals[i] que toman una imágen de featureVals[i] canales.\n",
        "      random_values_for_kernel = tf.truncated_normal([kernelVals[i], kernelVals[i], featureVals[i], featureVals[i + 1]], stddev=0.1)\n",
        "      \n",
        "      # Creamos una Variable (las Variables son los parametros del modelo)\n",
        "      kernel = tf.Variable(random_values_for_kernel)\n",
        "      \n",
        "      # Metemos la entrada pool a una layer convolucional con los filtros (kernel) generados\n",
        "      # Para que el tamaño de la imagen siga siendo el mismo ('SAME') se añaden pixels por los bordes (padding)\n",
        "      # Los filtros los aplican de pixel en pixel en cada dimensión (no termino de entender la 4ª dim., debe ser la de los filtros pero no veo como cuadra)\n",
        "      conv = tf.nn.conv2d(pool, kernel, padding='SAME',  strides=(1,1,1,1))\n",
        "      \n",
        "      # Despues de la convlución se normalizan los datos\n",
        "      conv_norm = tf.layers.batch_normalization(conv, training=self.is_train)\n",
        "      \n",
        "      # Se le aplica una no linearidad a los resultados\n",
        "      relu = tf.nn.relu(conv_norm)\n",
        "      \n",
        "      # Se reduce la imagen quedandonos con el mayor pixel de cada rectangulo de tamaño poolVals[i]\n",
        "      pool = tf.nn.max_pool(relu, (1, poolVals[i][0], poolVals[i][1], 1), (1, strideVals[i][0], strideVals[i][1], 1), 'VALID')\n",
        "\n",
        "    # Salida de la CNN\n",
        "    self.cnnOut4d = pool"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Oq0Y2kmJhzud",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Las Redes Neuronares Recurrentes (RNN) son capaces de entender contexto.\n",
        "\n",
        "Las más usadas son las Long-Short Term Memory que tienen en cuenta tanto el contexto en general como el contexto muy reciente. Aquí usaremos una bidireccional, para que entienda tanto el contexto de lo que ha pasado como el contexto de lo que está por venir."
      ]
    },
    {
      "metadata": {
        "id": "JcYRaPLeh0bT",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class Model(Model):\n",
        "  def setupRNN(self):\n",
        "    \"create RNN layers and return output of these layers\"\n",
        "    \n",
        "    # Se elimina la dimensión 2 del tensor, que solo tiene tamaño uno\n",
        "    rnnIn3d = tf.squeeze(self.cnnOut4d, axis=[2])\n",
        "\n",
        "    # basic cells which is used to build RNN\n",
        "    # TODO: estudiar si las CUDNNLSTM se pueden usar aquí para mejorar eficiencia\n",
        "    numHidden = 256\n",
        "    cells = [tf.contrib.rnn.LSTMCell(num_units=numHidden, state_is_tuple=True) for _ in range(2)] # 2 layers\n",
        "\n",
        "    # stack basic cells\n",
        "    stacked = tf.contrib.rnn.MultiRNNCell(cells, state_is_tuple=True)\n",
        "\n",
        "    # Creamos una LSTM bidireccional cuya entrada es de tamaño (nº de ejemplos por batch)x(Tiempo)x(nº de caracteristicas)\n",
        "    # BxTxF -> BxTx2H\n",
        "    ((fw, bw), _) = tf.nn.bidirectional_dynamic_rnn(cell_fw=stacked, cell_bw=stacked, inputs=rnnIn3d, dtype=rnnIn3d.dtype)\n",
        "    \n",
        "    # Concatenamos las salidas de la BLSTM y añadimos una dimension (why?)\n",
        "    # BxTxH + BxTxH -> BxTx2H -> BxTx1X2H\n",
        "    concat = tf.expand_dims(tf.concat([fw, bw], 2), 2)\n",
        "                  \n",
        "    # Pasamos un filtro que a cada instante de tiempo (parte de la imagen) le asigna una letra o un carater especial '-'\n",
        "    # project output to chars (including blank): BxTx1x2H -> BxTx1xC -> BxTxC\n",
        "    kernel = tf.Variable(tf.truncated_normal([1, 1, numHidden * 2, len(self.charList) + 1], stddev=0.1))\n",
        "    self.rnnOut3d = tf.squeeze(tf.nn.atrous_conv2d(value=concat, filters=kernel, rate=1, padding='SAME'), axis=[2])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "N-Dfib6PqyjD",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Varias partes de la imagen se convertirán en la misma letra, los espacios entre las letras se convertirán en el caracter especial '-'.\n",
        "\n",
        "Para hacer cuadrar esta salida con palabras se usa una Connectionist Temporal Classification que decide que palabras tienen más probabilidades.\n",
        "\n",
        "Esta red está especialmente pensada para poder entrenar la red."
      ]
    },
    {
      "metadata": {
        "id": "An7wBt7wqwjU",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class Model(Model):\n",
        "  def setupCTC(self):\n",
        "    \"create CTC loss and decoder and return them\"\n",
        "    # BxTxC -> TxBxC\n",
        "    self.ctcIn3dTBC = tf.transpose(self.rnnOut3d, [1, 0, 2])\n",
        "    \n",
        "    # ground truth text as sparse tensor\n",
        "    # Texto real etiquetado (bueno, un placeholder para ello)\n",
        "    self.gtTexts = tf.SparseTensor(tf.placeholder(tf.int64, shape=[None, 2]) , tf.placeholder(tf.int32, [None]), tf.placeholder(tf.int64, [2]))\n",
        "\n",
        "    # calc loss for batch\n",
        "    self.seqLen = tf.placeholder(tf.int32, [None])\n",
        "    # Se calcula el error medio cometido en la predicción\n",
        "    # Esta loss es la que se optimiza en __init__\n",
        "    self.loss = tf.reduce_mean(tf.nn.ctc_loss(labels=self.gtTexts, inputs=self.ctcIn3dTBC, sequence_length=self.seqLen, ctc_merge_repeated=True))\n",
        "\n",
        "    # calc loss for each element to compute label probability\n",
        "    self.savedCtcInput  = tf.placeholder(tf.float32, shape=[Model.maxTextLen, None, len(self.charList) + 1]) # Esto es basicamente self.ctcIn3dTBC\n",
        "    self.lossPerElement = tf.nn.ctc_loss(labels=self.gtTexts, inputs=self.savedCtcInput, sequence_length=self.seqLen, ctc_merge_repeated=True)\n",
        "\n",
        "    # Busca la palabra más razonalble basandos en la predicción hecha hasta ahora\n",
        "    # decoder: either best path decoding or beam search decoding\n",
        "    if self.decoderType == DecoderType.BestPath:\n",
        "      self.decoder = tf.nn.ctc_greedy_decoder(inputs=self.ctcIn3dTBC, sequence_length=self.seqLen)\n",
        "    elif self.decoderType == DecoderType.BeamSearch:\n",
        "      self.decoder = tf.nn.ctc_beam_search_decoder(inputs=self.ctcIn3dTBC, sequence_length=self.seqLen, beam_width=50, merge_repeated=False)\n",
        "    elif self.decoderType == DecoderType.WordBeamSearch:\n",
        "      # import compiled word beam search operation (see https://github.com/githubharald/CTCWordBeamSearch)\n",
        "      word_beam_search_module = tf.load_op_library('TFWordBeamSearch.so')\n",
        "\n",
        "      # prepare information about language (dictionary, characters in dataset, characters forming words) \n",
        "      chars = str().join(self.charList)\n",
        "      wordChars = open('../model/wordCharList.txt').read().splitlines()[0] # Documento con todas las letras\n",
        "      corpus = open('../data/corpus.txt').read()  # En este documento hay mucho texto en inglés.\n",
        "\n",
        "      # decode using the \"Words\" mode of word beam search\n",
        "      self.decoder = word_beam_search_module.word_beam_search(tf.nn.softmax(self.ctcIn3dTBC, dim=2), 50, 'Words', 0.0, corpus.encode('utf8'), chars.encode('utf8'), wordChars.encode('utf8'))\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "CDY_3nvv2lJE",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class Model(Model):\n",
        "  def setupTF(self):\n",
        "    \"\"\"\n",
        "    initialize TF\n",
        "    \n",
        "    Crea una sesion de TensorFlow e inicializa los parámetros (aleatoriamente o partir de un fichero).\n",
        "    Devuelve la sesion y un saver para guardar los parámetros.\n",
        "    \"\"\"\n",
        "    \n",
        "    print('Tensorflow: ' + tf.__version__)\n",
        "\n",
        "    # Crea una sesion TensorFlow\n",
        "    # Las sesiones se necesitan para cmputar los grafos de computación generados\n",
        "    sess = tf.Session() # TF session\n",
        "\n",
        "    # Para guardar los parametros del modelo necesita un Saver\n",
        "    saver = tf.train.Saver(max_to_keep=1) # saver saves model to file\n",
        "    modelDir = '../model/'\n",
        "    latestSnapshot = tf.train.latest_checkpoint(modelDir) # is there a saved model?\n",
        "\n",
        "    # if model must be restored (for inference), there must be a snapshot\n",
        "    if self.mustRestore and not latestSnapshot:\n",
        "      raise Exception('No saved model found in: ' + modelDir)\n",
        "\n",
        "    # load saved model if available\n",
        "    if latestSnapshot:\n",
        "      print('Init with stored values from ' + latestSnapshot)\n",
        "      saver.restore(sess, latestSnapshot)\n",
        "    else:\n",
        "      print('Init with new values')\n",
        "      sess.run(tf.global_variables_initializer())\n",
        "\n",
        "    return (sess, saver)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "kosZqw1F2yj-",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class Model(Model):\n",
        "  def toSparse(self, texts):\n",
        "    \"put ground truth texts into sparse tensor for ctc_loss\"\n",
        "    # Los sparse tensors solo guardan unos pocos valores del tensor con sus indices y asumen que el resto son  0s\n",
        "    # La CTC solo admite labels en este formato (las CTC dejan bastante que desear en TF/Keras)\n",
        "    # La conversión a tf.sparse.SparseTensor se hace en setupCTC (no me parece buena idea, no se porque no se puede hacer aquí)\n",
        "    indices = []\n",
        "    values  = []\n",
        "    shape   = [len(texts), 0] # last entry must be max(labelList[i])\n",
        "\n",
        "    # go over all texts\n",
        "    for (batchElement, text) in enumerate(texts):\n",
        "      # convert to string of label (i.e. class-ids)\n",
        "      labelStr = [self.charList.index(c) for c in text]\n",
        "      \n",
        "      # sparse tensor must have size of max. label-string\n",
        "      # Calculamos el tamaño máximo de las labelStr y lo guardamos en shape\n",
        "      if len(labelStr) > shape[1]:\n",
        "        shape[1] = len(labelStr)\n",
        "\n",
        "      # put each label into sparse tensor\n",
        "      for (i, label) in enumerate(labelStr):\n",
        "        indices.append([batchElement, i])\n",
        "        values.append(label)\n",
        "\n",
        "    return (indices, values, shape)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Qyn-B6-62wiT",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class Model(Model):\n",
        "  def decoderOutputToText(self, ctcOutput, batchSize):\n",
        "    \"extract texts from output of CTC decoder\"\n",
        "    \n",
        "    # contains string of labels for each batch element\n",
        "    encodedLabelStrs = [[] for i in range(batchSize)]\n",
        "\n",
        "    # word beam search: label strings terminated by blank\n",
        "    if self.decoderType == DecoderType.WordBeamSearch: \n",
        "      # Se eliminan los blanks detectados\n",
        "      blank = len(self.charList)\n",
        "      for batch in range(batchSize):\n",
        "        for label in ctcOutput[batch]:\n",
        "          if label == blank:\n",
        "            break\n",
        "          encodedLabelStrs[batch].append(label)\n",
        "\n",
        "    # TF decoders: label strings are contained in sparse tensor\n",
        "    else:\n",
        "      # ctc returns tuple, first element is SparseTensor \n",
        "      decoded = ctcOutput[0][0]\n",
        "\n",
        "      # go over all indices and save mapping: batch -> values\n",
        "      idxDict = { batch : [] for batch in range(batchSize) } #TODO: remove\n",
        "      for (idx, idx2d) in enumerate(decoded.indices):\n",
        "        label = decoded.values[idx]\n",
        "        batchElement = idx2d[0] # index according to [b,t]\n",
        "        encodedLabelStrs[batchElement].append(label)\n",
        "\n",
        "    # map labels to chars for all batch elements\n",
        "    return [str().join([self.charList[c] for c in labelStr]) for labelStr in encodedLabelStrs]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "tIXoTHoS2tcV",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class Model(Model):\n",
        "  def trainBatch(self, batch):\n",
        "    \"feed a batch into the NN to train it\"\n",
        "    # Nº de elementos por batch\n",
        "    numBatchElements = len(batch.imgs)\n",
        "    \n",
        "    # Etiquetas en formato sparse (todavia no convertido a SparseTensor)\n",
        "    sparseGT = self.toSparse(batch.gtTexts)\n",
        "    \n",
        "    # Ratio de aprendizaje. Decrece conforme entrenamos el modelo.\n",
        "    rate = 0.01 if self.batchesTrained < 10 else (0.001 if self.batchesTrained < 10000 else 0.0001) # decay learning rate\n",
        "    \n",
        "    # Diccionario indicando el valor de todos los placeholders que necesitamos para ejecutar self.optimizer y self.loss\n",
        "    feedDict = {self.inputImgs : batch.imgs,                         # Imágenes de ejemplo para entrenar\n",
        "                self.gtTexts : sparseGT,                             # Etiquetas de los ejemplos\n",
        "                self.seqLen : [Model.maxTextLen] * numBatchElements, # Tamaño de las predicciones\n",
        "                self.learningRate : rate,                            # Ratio de aprendizaje\n",
        "                self.is_train: True}                                 # Si estamos entrenando o no\n",
        "    \n",
        "    # Se ejecuta (aquí sí, ya no estamos creando el grafo de computación) la optimización y la precisión de la predicción\n",
        "    ( _ , lossVal) = self.sess.run([self.optimizer, self.loss], feedDict)\n",
        "    \n",
        "    self.batchesTrained += 1\n",
        "    \n",
        "    return lossVal"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "2mYvbZay2q2M",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class Model(Model):\n",
        "  def inferBatch(self, batch, calcProbability=False, probabilityOfGT=False):\n",
        "    \"feed a batch into the NN to recognize the texts\"\n",
        "\n",
        "    # decode, optionally save RNN output\n",
        "    # Nº de elementos por batch\n",
        "    numBatchElements = len(batch.imgs)\n",
        "\n",
        "    # Diccionario indicando el valor de todos los placeholders que necesitamos para ejecutar self.decoder y self.ctcIn3dTBC\n",
        "    feedDict = {self.inputImgs : batch.imgs,\n",
        "                self.seqLen : [Model.maxTextLen] * numBatchElements,\n",
        "                self.is_train: False}\n",
        "\n",
        "    # Ejecutamos los grafos de computación\n",
        "    evalRes = self.sess.run([self.decoder, self.ctcIn3dTBC], feedDict) # TODO: self.ctcIn3dTBC solo necesita ejecutarse si calcProbability\n",
        "\n",
        "    # Extraemos el texto de los resultados\n",
        "    texts = self.decoderOutputToText(evalRes[0], numBatchElements)\n",
        "\n",
        "    # feed RNN output and recognized text into CTC loss to compute labeling probability\n",
        "    probs = None\n",
        "    if calcProbability:\n",
        "      sparse = self.toSparse(batch.gtTexts) if probabilityOfGT else self.toSparse(texts)\n",
        "      ctcInput = evalRes[1]\n",
        "\n",
        "      # Diccionario indicando el valor de todos los placeholders que necesitamos para ejecutar self.lossPerElement\n",
        "      feedDict = {self.savedCtcInput : ctcInput,\n",
        "                  self.gtTexts : sparse,\n",
        "                  self.seqLen : [Model.maxTextLen] * numBatchElements,\n",
        "                  self.is_train: False}\n",
        "\n",
        "      lossVals = self.sess.run(self.lossPerElement, feedDict)\n",
        "\n",
        "      probs = np.exp(-lossVals)\n",
        "\n",
        "    return (texts, probs)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "eSui079v2okA",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class Model(Model):\n",
        "  def save(self):\n",
        "    \"save model to file\"\n",
        "    self.snapID += 1\n",
        "    self.saver.save(self.sess, '../model/snapshot', global_step=self.snapID)"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}